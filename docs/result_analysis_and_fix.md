# 实验结果异常分析与修复方案

在引入“动态惩罚模型”后，实验结果显示 MEDIA 和 Ours 算法在线性模型（BERT, ViT）上的性能反而劣于基础算法 DINA（例如 ViT: MEDIA 2046ms vs DINA 1618ms）。以下是对该异常现象的深度分析及修复方案。

## 1. 为了什么会出现性能倒挂？

### A. 根本原因：分区器与调度器的“认知偏差”

1.  **分区器（Partitioner）的视角（MEDIA/Ours 的决策逻辑）**：
    *   在决定是否合并两个分区 $P_1, P_2$ 时，算法比较：
        *   **合并代价**：$Cost_{merge} = (W_1 + W_2) \times Penalty$
        *   **分离代价**：$Cost_{split} = W_1 + W_2 + Comm$
    *   **隐含假设**：算法默认“如果我不把它们合并，它们就会产生通信开销”。
    *   **决策**：只要 $Penalty < Comm$，算法就会选择合并。

2.  **调度器（Scheduler）的实际行为**：
    *   在执行阶段，调度器（无论是 DINA 还是 Ours 的调度器）是非常智能的。
    *   对于线性依赖 $P_1 \to P_2$，如果服务器 $S_1$ 执行完 $P_1$ 后变空闲，调度器会优先将 $P_2$ 也分配给 $S_1$。
    *   **实际后果**：**同机执行（Same-Server Execution）使得通信开销 $ActualComm = 0$**。

3.  **冲突爆发**：
    *   MEDIA 为了节省“预想中的通信（几百毫秒）”，选择了“昂贵的换页（几百毫秒）”。
    *   结果：通信并没有发生（省了个寂寞），但换页惩罚却是实实在在地发生了。
    *   最终：$Time_{MEDIA} = Work + Penalty > Work = Time_{DINA}$。

## 2. 为什么在旧参数下没暴露？
*   **旧参数（2x 惩罚 + 贪心）**：
    *   在旧参数下，MEDIA 发现合并后的惩罚并没有比通信大太多，或者因为逻辑过于简化，巧合地没有触发大量错误合并。
    *   更重要的是，在之前的 InceptionV3 案例中，MEDIA 也没能赢过 DINA，只是打平。这暗示了“错误合并”可能一直存在，只是在动态惩罚放大后（Penalty > 3.0x），错误的代价变得肉眼可见。

## 3. 修复方案：修正通信预期权重

为了纠正分区器的“悲观通信预期”，我们需要在代价函数中引入一个 **通信概率权重（Communication Probability Weight）**。

### 修正后的启发式逻辑
我们不再假设 $Split \implies Comm$，而是认为 $Split \implies p \times Comm$。

*   **参数**: `COMM_WEIGHT` (建议值 0.1 ~ 0.5)
    *   这代表算法认为“如果不合并，只有 10%-50% 的概率真的需要跨机传输”。
    *   在线性链式模型中，这个概率接近 0。在分叉模型中，这个概率较高。

*   **新决策公式**:
    ```python
    if penalty_delta < comm_time * COMM_WEIGHT:
        Merge()
    else:
        Split()
    ```

### 预期效果
*   对于 **ViT/BERT (线性)**：
    *   $Penalty$ 很高，而 $Comm \times 0.2$ 很小。
    *   MEDIA 会判断“不值得合并”，从而选择切分。
    *   结果：MEDIA 回归到 DINA 的行为，消除了性能倒挂。
*   对于 **Inception (并行)**：
    *   Ours 算法本身主要靠并行获利，而非超限合并。
    *   该修正会防止 Ours 在单条分支内部进行不必要的超限合并，进一步优化子任务的纯净度。

## 4. 实施步骤
1.  在 `alg_media.py` 和 `alg_ours.py` 中引入 `COMM_INF_WEIGHT = 0.2`（保守估计）。
2.  修改合并判断逻辑。
3.  重新运行实验验证。
