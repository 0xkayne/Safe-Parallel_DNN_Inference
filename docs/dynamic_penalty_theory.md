# 基于前沿研究的 SGX 动态换页惩罚模型理论分析

本文档基于学术界对 Intel SGX 扩展内存管理（Paging）的最新研究成果（如 Glamdring, Eleos, Maestro 等），设计了一套适用于 DNN 推理任务的动态惩罚模型。

## 1. 理论基础：为什么是线性而非指数？

在通用计算场景下，当工作集（Working Set）超过物理内存时，通常会发生“颠簸”（Thrashing），导致性能指数级下降。然而，针对 DNN 推理任务，研究表明其具有特殊的**访存模式（Access Pattern）**：

1.  **分块平铺（Tiling/Blocking）**: 现代 DNN 库（如 DNNL, TensorFlow-Lite）会对卷积矩阵乘法进行分块优化。
2.  **流式访问（Streaming）**: 权重矩阵通常只被扫描一次（或少数几次），而不是随机跳跃访问。

**关键结论**：对于经过优化的 DNN 任务，SGX 的换页开销主要来自于**数据加密/解密带宽的瓶颈**，而不是页表抖动。因此，性能衰减与“超限内存量”呈现**强线性相关**关系，而非指数关系。

## 2. 拟定模型：带基数的线性增长模型

我们提出以下分段函数来模拟真实的 EPC 换页惩罚：

$$
Penalty(r) = 
\begin{cases} 
1.0 & \text{if } r \le 1 \\
1.0 + \delta + \gamma \times (r - 1) & \text{if } r > 1 
\end{cases}
$$

其中：
*   $r = \frac{Memory_{required}}{EPC_{effective}}$：内存超限比率。
*   $\delta$ (**基础开销系数**): 代表触发换页机制本身的固定开销（此为“门槛效应”，一旦触发 paging，就需要启用 SGX 驱动的 user/kernel 模式切换和 EWB/ELDU 指令序列）。
    *   *设定值*: **0.5** (即一旦超限，性能立即下降 50%)。
*   $\gamma$ (**带宽衰减斜率**): 代表数据加解密吞吐量相对于纯内存带宽的比例。SGX 的内存加密引擎（MEE）带宽通常仅为 DRAM 带宽的 1/3 到 1/4。这意味着每多 1MB 数据需要换页，就会引入约 3-4 倍于正常内存访问的延迟。
    *   *设定值*: **3.0**。

## 3. 模型验证与示例

| 内存超限比 ($r$) | 计算公式 | 惩罚因子 ($P$) | 对比旧模型 (2.0x) | 物理含义解读 |
| :--- | :--- | :--- | :--- | :--- |
| **1.0 (93MB)** | $1.0$ | **1.0x** | 1.0x | 完全在 EPC 内运行，无损耗。 |
| **1.1 (102MB)** | $1 + 0.5 + 3 \times 0.1$ | **1.8x** | 2.0x (旧模型偏悲观) | 轻微超限，引入了上下文切换开销，但数据搬运量小。 |
| **1.5 (140MB)** | $1 + 0.5 + 3 \times 0.5$ | **3.0x** | 2.0x (旧模型严重乐观) | 数据搬运成为瓶颈，耗时变为 3 倍。 |
| **2.0 (186MB)** | $1 + 0.5 + 3 \times 1.0$ | **4.5x** | 2.0x (旧模型严重乐观) | 内存需求翻倍，系统花费大量时间在 EWB/ELDU 上，计算占比极低。 |
| **3.0 (279MB)** | $1 + 0.5 + 3 \times 2.0$ | **7.5x** | 2.0x | 严重超限，基本不可用。 |

## 4. 对算法的影响预测

1.  **DINA**: 不受影响，因为它强制切分，永远不超限。
2.  **MEDIA / Ours**:
    *   在旧模型下，MEDIA 可能会认为“超限惩罚只有 2x”，从而为了省去“几次通信”而合并一个大分区（例如 200MB）。
    *   在新模型下，200MB 的惩罚高达 **5.0x** 以上。MEDIA 会计算发现 $T_{comp} \times 5 \gg T_{comm}$，从而**拒绝合并**。
    *   **预期结果**：MEDIA 和 Ours 的分区策略将更加精细，倾向于在“稍稍超限”和“切分通信”之间找到更优的平衡点，而不是无脑合并。

## 5. 实施计划

我们将修改 `common.py`，增加 `calculate_penalty` 函数，并在所有算法中调用此函数替代硬编码的 `0.5`。
